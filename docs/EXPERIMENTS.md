#  Experimentos y Resultados

## Descripci贸n de Experimentos

Este documento describe los experimentos realizados y los resultados obtenidos.

## Estructura de Experimentos

### 1. Configuraci贸n de Capas Ocultas

**Objetivo**: Determinar el impacto del n煤mero y tama帽o de capas ocultas.

**Configuraciones probadas**:
- 1 capa: [32], [64], [128]
- 2 capas: [64, 32], [128, 64], [256, 128]
- 3 capas: [128, 64, 32], [256, 128, 64]
- 4+ capas: [512, 256, 128, 64]

**M茅tricas evaluadas**:
- Precisi贸n de entrenamiento
- Precisi贸n de prueba
- Tiempo de entrenamiento
- N煤mero de 茅pocas hasta convergencia

**Hip贸tesis**:
- M谩s capas = mayor capacidad de aprendizaje
- Riesgo de overfitting con demasiadas capas
- Trade-off entre precisi贸n y tiempo de entrenamiento

### 2. Tasa de Aprendizaje

**Objetivo**: Encontrar la tasa de aprendizaje 贸ptima.

**Valores probados**:
- 0.001 (muy bajo)
- 0.01 (bajo)
- 0.1 (medio)
- 0.5 (alto)
- 0.75 (muy alto)
- 1.0 (extremo)

**M茅tricas evaluadas**:
- Velocidad de convergencia
- Estabilidad del entrenamiento
- Precisi贸n final

**Hip贸tesis**:
- LR muy bajo = convergencia lenta
- LR muy alto = inestabilidad, no converge
- LR 贸ptimo = balance entre velocidad y estabilidad

### 3. Funciones de Activaci贸n

**Objetivo**: Comparar diferentes funciones de activaci贸n.

**Funciones probadas**:
- Sigmoid: cl谩sica, range [0, 1]
- Tanh: range [-1, 1], mejor gradiente
- ReLU: m谩s r谩pida, evita vanishing gradient

**M茅tricas evaluadas**:
- Velocidad de convergencia
- Precisi贸n final
- Estabilidad num茅rica

### 4. Robustez al Ruido

**Objetivo**: Evaluar la resistencia del modelo a datos corruptos.

**Tipos de ruido**:
- Gaussiano: ruido aleatorio normal
- Salt & Pepper: p铆xeles blancos/negros aleatorios
- Speckle: ruido multiplicativo
- Uniforme: ruido distribuido uniformemente

**Niveles probados**: 0.05, 0.1, 0.15, 0.2

**M茅tricas evaluadas**:
- Precisi贸n en datos limpios
- Precisi贸n en datos ruidosos
- Degradaci贸n de rendimiento
- Puntuaci贸n de robustez (noisy_acc / clean_acc)

## Resultados Esperados

### Configuraci贸n ptima Esperada

Basado en la literatura y experimentos previos:

```
Arquitectura 贸ptima:
- Capas ocultas: [128, 64] o [256, 128]
- Tasa de aprendizaje: 0.01 - 0.1
- Funci贸n de activaci贸n: Tanh o ReLU
- Batch size: 64
- pocas: 50-100

Rendimiento esperado:
- Precisi贸n de entrenamiento: 98-99%
- Precisi贸n de prueba: 95-97%
- Tiempo de entrenamiento: 30-120 segundos
```

### M茅tricas de xito

- **Excelente**: Test accuracy > 95%
- **Bueno**: Test accuracy 90-95%
- **Aceptable**: Test accuracy 85-90%
- **Necesita mejora**: Test accuracy < 85%

### Generalization Gap

- **Excelente**: Gap < 2%
- **Bueno**: Gap 2-5%
- **Overfitting**: Gap > 5%

## An谩lisis de Trade-offs

### 1. Complejidad vs Rendimiento

```
Modelo Simple [64]:
+ R谩pido de entrenar
+ Menos par谩metros
- Menor capacidad

Modelo Profundo [512, 256, 128, 64]:
+ Mayor capacidad
+ Mejor precisi贸n potencial
- M谩s lento
- Riesgo de overfitting
```

### 2. Velocidad vs Precisi贸n

```
Alta LR (0.5-1.0):
+ Convergencia r谩pida
- Puede oscilar
- Puede no encontrar 贸ptimo

Baja LR (0.001-0.01):
+ Convergencia estable
+ Mejor precisi贸n final
- Entrenamiento lento
```

## Visualizaciones Generadas

### Por Experimento

1. **Training History**
   - Curvas de p茅rdida (entrenamiento y validaci贸n)
   - Curvas de precisi贸n
   - Tiempo por 茅poca

2. **Confusion Matrix**
   - Matriz absoluta (counts)
   - Matriz normalizada (%)
   - Identificaci贸n de pares confundidos

3. **Decision Boundary**
   - Proyecci贸n PCA a 2D
   - Regiones de decisi贸n coloreadas
   - Muestras superpuestas

4. **Loss Landscape**
   - Superficie 3D de p茅rdida
   - Contornos 2D
   - Punto actual marcado

5. **Weight Distributions**
   - Histogramas por capa
   - Estad铆sticas (media, std)
   - Evoluci贸n durante entrenamiento

## Formato de Reportes

### Reporte Individual (por modelo)

```
1. ARQUITECTURA
   - Detalles de capas
   - Total de par谩metros

2. ESTADSTICAS DE PESOS
   - Por capa: media, std, min, max

3. DINMICA DE ENTRENAMIENTO
   - Reducci贸n de p茅rdida
   - Mejora de precisi贸n
   - Tiempo de entrenamiento

4. MTRICAS DE RENDIMIENTO
   - Precisi贸n train/test
   - Gap de generalizaci贸n
   - Estado (overfitting/underfitting)

5. MTRICAS DETALLADAS
   - Precision, Recall, F1 por clase
   - Matriz de confusi贸n
   - Pares m谩s confundidos

6. ANLISIS ESTADSTICO
   - Confianza promedio
   - Diferencia de confianza (correctos vs incorrectos)

7. ANLISIS DE CONVERGENCIA
   - Gradiente de p茅rdida
   - Estado de convergencia
```

### Reporte Comparativo

```
1. ESTADSTICAS RESUMIDAS
   - Mejor/peor/promedio por m茅trica

2. TOP 5 CONFIGURACIONES
   - Detalles de cada una
   - M茅tricas clave

3. ANLISIS DE TRADE-OFFS
   - Precisi贸n vs tiempo
   - Complejidad vs rendimiento
```

## Conclusiones y Recomendaciones

(Se completar谩 despu茅s de ejecutar experimentos)

### Configuraci贸n Recomendada

```
Para uso general en MNIST:
- Capas: [128, 64]
- LR: 0.01
- Activation: sigmoid o tanh
- Epochs: 50-100
- Batch size: 64
```

### Lecciones Aprendidas

1. **Arquitectura**
   - ...

2. **Hiperpar谩metros**
   - ...

3. **Robustez**
   - ...

## Referencias

- LeCun, Y., et al. (1998). Gradient-based learning applied to document recognition.
- Glorot, X., & Bengio, Y. (2010). Understanding the difficulty of training deep feedforward neural networks.
- He, K., et al. (2015). Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification.
