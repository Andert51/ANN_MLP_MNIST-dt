# ğŸ§  MLP-MNIST Experimentation Framework

<div align="center">

**Advanced Multi-Layer Perceptron Experimentation System for MNIST Digit Recognition**

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Active-success.svg)](.)

[Features](#-features) â€¢ [Installation](#-installation) â€¢ [Quick Start](#-quick-start) â€¢ [Documentation](#-documentation) â€¢ [Examples](#-examples)

</div>

---

## ğŸ“‹ Overview

A comprehensive, visually stunning framework for experimenting with Multi-Layer Perceptrons (MLPs) on the MNIST dataset. This system provides:

- ğŸ¨ **Beautiful terminal UI** powered by Rich
- ğŸ“Š **Advanced visualizations** including heatmaps, confusion matrices, decision boundaries, and loss landscapes
- ğŸ”¬ **Extensive experimentation** tools for hyperparameter exploration
- ğŸ¯ **Noise robustness testing** with multiple noise types
- ğŸ“ˆ **Detailed mathematical reports** with statistical analysis
- ğŸ¬ **Training animations** to visualize the learning process
- ğŸŒ **Interactive dashboards** with Plotly

## âœ¨ Features

### ğŸ¯ Core Capabilities

- **Multiple Experiment Types**
  - Layer configuration analysis (1-5 hidden layers)
  - Learning rate exploration (0.001 - 1.5)
  - Activation function comparison (sigmoid, tanh, ReLU)
  - Comprehensive random search
  - Noise robustness testing

- **Advanced Visualizations**
  - ğŸ“Š Dataset sample visualization
  - ï¿½ï¸ **MNIST Dataset Overview** (NEW! - comprehensive dataset analysis)
  - ğŸ§  **Network Topology Animation** (NEW! - animated neuron activation flow)
  - ï¿½ğŸ“ˆ Training history curves (loss, accuracy, time)
  - ğŸ”² Confusion matrices (normalized & raw)
  - ğŸ¯ Prediction samples with confidence scores
  - ğŸŒ¡ï¸ Probability heatmaps
  - âš–ï¸ Weight distribution analysis
  - ğŸ—ºï¸ Decision boundary plots (PCA projection)
  - ğŸ”ï¸ Loss landscape visualization (2D & 3D)
  - ğŸ¬ Training animations (GIF)
  - ğŸ“Š Interactive dashboards (HTML)
  - ğŸ”Š Clean vs noisy data comparison

- **Noise Analysis**
  - Gaussian noise
  - Salt & Pepper noise
  - Speckle noise
  - Uniform noise
  - Configurable noise levels

- **Mathematical Reports**
  - Comprehensive architecture analysis
  - Weight statistics per layer
  - Training dynamics metrics
  - Performance evaluation
  - Detailed classification metrics
  - Confusion matrix analysis
  - Statistical tests
  - Convergence analysis

### ğŸ¨ User Interface

- Beautiful ASCII art banner
- Color-coded terminal output
- Progress bars with time estimates
- Interactive menus with rich formatting
- Tabular result displays
- Real-time experiment tracking

## ğŸš€ Installation

### Prerequisites

- Python 3.8 or higher
- pip package manager

### Setup

1. **Clone or navigate to the project**
   ```bash
   cd T2_MLP-MNIST
   ```

2. **Create virtual environment (recommended)**
   ```bash
   python -m venv venv
   
   # Windows
   .\venv\Scripts\activate
   
   # Linux/Mac
   source venv/bin/activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

## ğŸ¯ Quick Start

### Option 1: Interactive Application

Run the main interactive application:

```bash
python main.py
```

This launches a beautiful terminal UI with a main menu offering:
1. Quick Experiment
2. Layer Configuration Analysis
3. Learning Rate Exploration
4. Activation Function Comparison
5. Comprehensive Grid Search
6. Noise Robustness Testing
7. Configure Settings
8. Load Previous Results

### Option 2: Quick Start Script

For a simple demonstration:

```bash
python scripts/quick_start.py
```

This will:
- Load 2000 MNIST samples
- Train an MLP with [128, 64] architecture
- Generate all visualizations
- Create a mathematical report

Expected output in `output/images/`:
- Dataset samples
- Training history
- Confusion matrix
- Prediction samples
- Probability heatmap
- Weight distributions
- Decision boundary
- Loss landscape

### Option 3: Advanced Experiment

For comprehensive analysis:

```bash
python scripts/advanced_experiment.py
```

This performs:
- Layer configuration experiments (8 configs)
- Learning rate experiments (5 rates)
- Activation function comparison (2 functions)
- Full visualization suite
- Comparative analysis report

### Option 4: New Topology & Dataset Demo ğŸ†•

To explore the new visualization features:

```bash
python scripts/topology_demo.py
```

**What's New:**

1. **ğŸ§  Network Topology Animation**
   - Animated visualization of neural network structure
   - Shows real-time neuron activation as data flows through layers
   - Color-coded activation levels (red=high, green=low)
   - Displays prediction confidence and process
   - Creates GIF animations for multiple predictions

2. **ğŸ–¼ï¸ MNIST Dataset Overview**
   - Comprehensive dataset visualization
   - Class distribution (bar & pie charts)
   - Dataset statistics (mean, std, min, max)
   - Sample images for all 10 digits
   - Visual quality assessment

**Demo Output:**
- `mnist_dataset_overview.png` - Complete dataset analysis
- `network_topology_animation_[1-5].gif` - 5 animated network predictions
- See neurons "light up" as they process information!

This demo is perfect for:
- Understanding how neural networks work internally
- Presenting the model architecture visually
- Analyzing dataset characteristics
- Educational demonstrations
- Academic presentations

## ğŸ“š Documentation

### Project Structure

```
T2_MLP-MNIST/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py              # Configuration classes
â”‚   â”œâ”€â”€ data_loader.py         # MNIST loading & noise generation
â”‚   â”œâ”€â”€ mlp_model.py           # MLP implementation
â”‚   â”œâ”€â”€ experiments.py         # Experiment runner
â”‚   â”œâ”€â”€ visualizations.py      # Visualization suite
â”‚   â”œâ”€â”€ reports.py             # Mathematical reporting
â”‚   â””â”€â”€ ui.py                  # Interactive UI
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ quick_start.py         # Quick demo
â”‚   â”œâ”€â”€ advanced_experiment.py # Comprehensive experiments
â”‚   â”œâ”€â”€ batch_experiment.py    # All experiments runner
â”‚   â”œâ”€â”€ noise_demo.py          # Noise comparison demo
â”‚   â””â”€â”€ topology_demo.py       # NEW! Network topology & dataset visualization demo
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ images/                # Generated visualizations
â”‚   â””â”€â”€ data/                  # Experiment results & reports
â”œâ”€â”€ main.py                    # Main application
â”œâ”€â”€ requirements.txt           # Dependencies
â””â”€â”€ README.md                  # This file
```

### Configuration Examples

#### Dataset Configuration

```python
from src.config import DatasetConfig

config = DatasetConfig(
    n_samples=5000,        # Number of samples
    test_size=0.2,         # Test split ratio
    normalize=True,        # Normalize pixels [0-1]
    random_seed=42         # Reproducibility
)
```

#### MLP Configuration

```python
from src.config import MLPConfig

config = MLPConfig(
    hidden_layers=[128, 64],    # Architecture
    learning_rate=0.01,         # Learning rate
    activation="sigmoid",       # sigmoid, tanh, relu
    max_epochs=100,             # Maximum epochs
    batch_size=64,              # Mini-batch size
    tolerance=1e-4,             # Early stopping
    random_seed=42
)
```

## ğŸ¨ Visualizations Generated

The framework creates beautiful, publication-ready visualizations:

1. **Dataset Samples** - Grid view of MNIST digits
2. **Training History** - Loss and accuracy curves
3. **Confusion Matrix** - Model performance breakdown
4. **Prediction Samples** - Predictions with confidence
5. **Probability Heatmap** - Class probability distributions
6. **Weight Distributions** - Layer weight histograms
7. **Decision Boundary** - 2D decision regions (PCA)
8. **Loss Landscape** - 3D loss surface visualization
9. **Training Animation** - Learning process GIF
10. **Interactive Dashboard** - HTML dashboard with Plotly

## ğŸ“Š Mathematical Reports

Comprehensive text reports include:

- Network architecture details
- Weight statistics per layer
- Training dynamics and convergence
- Performance metrics (accuracy, loss, time)
- Per-class classification metrics
- Confusion matrix analysis
- Prediction confidence statistics
- Overfitting detection

## ğŸ“ Academic Use

Perfect for:
- ğŸ“ Research papers on neural network hyperparameters
- ğŸ“ Course projects demonstrating MLP concepts
- ğŸ”¬ Experimentation with various architectures
- ğŸ“Š Comparative analysis of training strategies

## ğŸ› ï¸ Troubleshooting

**Issue**: MNIST download fails
- Solution: Framework will retry and cache data automatically

**Issue**: Out of memory
- Solution: Reduce n_samples in DatasetConfig

**Issue**: Slow training
- Solution: Reduce max_epochs or use smaller architecture

## ğŸ“ˆ Performance Tips

1. Start with 1000-2000 samples for initial experiments
2. Use batch size of 32-64 for optimal performance
3. Start with learning rate of 0.01, adjust based on convergence
4. Early stopping is enabled by default (tolerance=1e-4)

## ğŸ¤ Contributing

Contributions welcome! Areas for enhancement:
- Additional activation functions
- More optimization algorithms
- Regularization techniques
- Other datasets (Fashion-MNIST, CIFAR-10)

## ğŸ“œ License

MIT License

## ğŸ‘¨â€ğŸ’» Author

**Eye of the Universe**
- Soft Computing Projects
- Universidad del Universo

---

<div align="center">

**Made with â¤ï¸ for Neural Network Research**

[â¬† Back to Top](#-mlp-mnist-experimentation-framework)

</div>
